# Ruby's Dilemma

![DubDub](https://img.shields.io/badge/WWDC-21-blue)  ![Swift](https://img.shields.io/badge/platform-SwftUI-red)   ![Xcode](https://img.shields.io/badge/Tool-Xcode-informational) ![Xcode](https://img.shields.io/badge/Status-Accepted-success)

Meet Ruby the Rabbit üê∞ and delve into her life as you experience this Swift Playground, written in the form of a playgroundbook. Stay with Ruby and help her in various activities until you find out that there's a stunning revelation waiting for you! 

![Thumbnal](https://i.lensdump.com/i/Zj5ItF.png)

## About my playground

My Swift playground is built as a Playground book using Xcode. Users must manually navigate through the pages of the playground book after each page is experienced. The first page of the book starts up with a simple SwiftUI View of the main character in the experience. Then, I used the AVFoundation framework to implement music and a video player.

And then, on the second page lies a SwiftUI View with texts, emojis, and buttons that provides a fun and interactive experience. The third page features an Augmented Reality (AR) view where the user is expected to point the iPad's camera at a plane surface and move around. For devices with LiDAR, the playground supports scene reconstruction, to make the job easier. The models are crafted using Reality Composer and are implemented using ARKit and RealityKit frameworks.

Once that is done, on the fourth page is yet another SwiftUI view with customized cards for a fun and thought-provoking Quiz session. It only comprises of three questions but all three of them will make you reconsider everything that has been experienced so far. And finally, on the fifth page of the book, is a stunning revelation and my two cents on the issue that is illustrated via the playground experience.

I have combined many swift frameworks into a bundle to provide a thought-provoking and entertaining experience which demonstrates a problem I thought was very alarming. Every asset seen in the experience is handcrafted; the animoji/memoji videos are shot using my iPhone, the AR models were designed using Reality Composer with custom behaviors, the music and all sounds used in the AR experience were composed using GarageBand on my iPad. No 3rd party assets or software was used.


Designed and Developed with ‚ù§Ô∏è for WWDC 2021 by Sabesh Bharathi

